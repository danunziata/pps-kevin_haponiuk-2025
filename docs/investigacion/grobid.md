# Introducci√≥n / Problem√°tica

n8n dispone de un nodo llamado `Extract from File` que permite m√∫ltiples opciones, entre ellas, **"extract from PDF"**. Inicialmente, el flujo del sistema consist√≠a en descargar cada paper y luego procesarlo con este nodo. Si bien este m√©todo es relativamente r√°pido para extraer texto plano desde un PDF, el **output no es preciso ni estructurado**.

Esto genera una gran desventaja cuando se busca trabajar los datos de forma organizada por cada paper, especialmente al intentar identificar secciones espec√≠ficas como introducci√≥n, metodolog√≠a, resultados, etc. ‚Äîcomo se estudi√≥ en `/investigacion/revision_biblio/`. Por lo tanto, se vuelve confuso y poco confiable para alimentar una base de datos vectorial, que luego ser√° utilizada en el sistema RAG para responder preguntas basadas en el contenido de los papers.

Ante esta necesidad, se exploraron soluciones m√°s robustas y espec√≠ficas para la lectura y estructuraci√≥n de art√≠culos cient√≠ficos en PDF. De esta b√∫squeda surge **GROBID**, una herramienta open-source, dockerizada y ampliamente adoptada en contextos acad√©micos y cient√≠ficos, que permite una extracci√≥n **estructurada y enriquecida** de los documentos.

<p align="center">
  <img src="/images/grobid-rag.png" width="100%">
  <br>
  <em>Figura 1: "Ilustraci√≥n de d√≥nde entrar√≠a GROBID en nuestro esquema"</em>
</p>

---

# ¬øQu√© es GROBID?

**GROBID** (GeneRation Of BIbliographic Data) es una herramienta de c√≥digo abierto basada en machine learning que permite extraer y estructurar informaci√≥n desde documentos cient√≠ficos en PDF. Est√° entrenado espec√≠ficamente en el **dominio acad√©mico**, por lo que reconoce con alta precisi√≥n elementos como:

- T√≠tulos
- Autores
- Afiliaciones
- Secciones del paper
- Citas bibliogr√°ficas
- Referencias cruzadas
- Figuras y ecuaciones

Su modelo se basa en t√©cnicas de **procesamiento de lenguaje natural (NLP)** y **CRF (Conditional Random Fields)** para el etiquetado de textos, lo cual lo convierte en una alternativa ideal para estructurar art√≠culos cient√≠ficos de forma autom√°tica.

---

## Nuestro uso

En nuestro proyecto, **utilizamos GROBID para transformar documentos PDF en archivos XML con estructura sem√°ntica**. Esto permite luego procesar los papers por secciones espec√≠ficas, enriquecer los res√∫menes autom√°ticos y alimentar la base de datos vectorial para responder preguntas con mayor precisi√≥n.

<p align="center">
  <img src="/images/grobid-pdf_xml.png" width="50%">
  <br>
  <em>Figura 2: "Conversi√≥n de PDF a XML estructurado mediante GROBID"</em>
</p>

---

# Instalaci√≥n

GROBID puede instalarse de varias formas:

# AGREGAR MANUALMENTE

Esta √∫ltima opci√≥n es la m√°s pr√°ctica, ya que permite levantar r√°pidamente el servicio sin preocuparse por dependencias.

---
Falta agregar las opciones que tiene GROBID y especificar que la que uso se llama processFulltextDocument

---

## Estructura del entorno de trabajo

En nuestro flujo, definimos una estructura simple con tres elementos clave:

- üìÅ input_papers # Carpeta que contiene los archivos PDF a procesar 
- üìÅ output_papers # Carpeta donde se guardar√°n los archivos XML generados por GROBID 
- üìÑ config.json # Archivo de configuraci√≥n del cliente GROBID 
- üìÑ cliente_grobid.py # Script Python para ejecutar la conversi√≥n masiva



---

## `üìÑ config.json`

Archivo necesario para establecer la configuraci√≥n del cliente. En nuestro caso, no requiere modificaci√≥n:


``````bash
    "grobid_server": "http://localhost:8070",
    "batch_size": 100,
    "sleep_time": 5,
    "timeout": 60,
    "coordinates": [ "persName", "figure", "ref", "biblStruct", "formula", "s", "note", "title" ]
``````


## `üìÑ cliente_grobid.py`

Este script ejecuta el cliente GROBID para transformar todos los archivos .pdf en la carpeta input_papers y guardar los .xml resultantes en output_papers.

from grobid_client.grobid_client import GrobidClient

``````bash
if __name__ == "__main__":
    client = GrobidClient(config_path="./config.json")
    client.process("processFulltextDocument", "input_papers", output="output_papers/", consolidate_citations=False, tei_coordinates=False, force=True)
``````


## Referencia

FALTA AGREGAR AC√Å