# n8n

**n8n** es una herramienta de automatizaci贸n de flujos de trabajo (*workflow automation*) basada en nodos, de c贸digo abierto y altamente personalizable. Permite conectar diferentes servicios, APIs y procesos de manera visual e intuitiva, ideal para integrar tareas complejas sin necesidad de escribir mucho c贸digo.

<p align="center">
  <img src="/images/workflow-n8n.gif" width="100%">
  <br>
  <em>Figura 1: Ejemplo Interfaz gr谩fica de n8n</em>
</p>


## Caracter铆sticas principales

- 锔 **Basado en nodos**: cada paso del flujo es un nodo que realiza una tarea (leer un archivo, hacer una petici贸n HTTP, analizar texto, etc.).
-  **Automatizaci贸n condicional**: permite bifurcar flujos seg煤n condiciones l贸gicas, errores, o datos.
-  **Integraci贸n con cientos de servicios**: Google Drive, APIs REST, bases de datos, herramientas de IA, entre otros.
-  **Extensible con c贸digo**: se pueden usar c贸digos JavaScript o Python personalizados.
-  **Self-hosted o en la nube**: puede desplegarse localmente, en servidores propios, o usar su versi贸n cloud.


## 驴C贸mo se usa?

### 1. Crear un nuevo flujo

Los flujos en n8n comienzan desde un nodo gatillo (trigger), como por ejemplo:

- Un archivo subido a Google Drive
- Una petici贸n entrante por HTTP
- Un webhook desde una aplicaci贸n externa
- mediante otro workflow


### 2. Encadenar nodos

Luego del nodo de inicio, se encadenan nodos de procesamiento:

- Transformaciones con nodos como `Set`, `Function`, `Merge`
- Interacciones externas como `HTTP Request`, `Google Sheets`, `Email`
- An谩lisis de datos, consultas a bases, o comunicaci贸n con APIs de IA


## Aplicaci贸n en este proyecto

En el contexto del presente proyecto, **n8n** se utiliza como motor de orquestaci贸n para automatizar tareas como:

-  **Esperar la notificaci贸n de petici贸n de procesamiento de papers**
-  **Ejecuci贸n GROBID para an谩lisis del paper**
-  **Generaci贸n de res煤menes o procesamiento necesario**
-  **Indexaci贸n de informaci贸n en la base de datos vectorial (Qdrant)**
-  **Interacci贸n con modelos de lenguaje (LLMs)**
-  **Interacci贸n con el usuario final**


## Ventajas de usar n8n en el proyecto

| Ventaja                       | Descripci贸n                                                                        |
| ----------------------------- | ---------------------------------------------------------------------------------- |
| **Ejecuci贸n Local**           | Permite el control total sin necesidad de pagos mensuales a aplicaciones externas. |
| **Automatizaci贸n sin c贸digo** | Reduce la necesidad de scripting manual.                                           |
| **Reutilizaci贸n de flujos**   | Se pueden guardar y clonar flujos.                                                 |
| **Integraci贸n r谩pida**        | Conexiones simples con m煤ltiples servicios.                                        |
| **Observabilidad**            | Logs visuales y control sobre cada nodo.                                           |
| **Control de errores**        | Permite manejar errores de forma precisa.                                          |

## Instalaci贸n

Para utilizar **n8n** existen distintas alternativas. La m谩s sencilla ser铆a usarlo directamente en la nube (**n8n cloud**); sin embargo, no optaremos por esta opci贸n debido a las limitaciones que presenta, especialmente en cuanto al manejo de *tokens* con modelos de IA y otras integraciones.
Nuestro objetivo es instalar **n8n** de manera **local**, lo que ofrece mayor control y escalabilidad. Actualmente, existen dos m茅todos principales para hacerlo (solo la instalaci贸n de n8n, pero luego se explica una tercer forma que implica un **Self-hosted AI starter kit** que incluye unas caracteristicas adicionales):

### 1. **Instalaci贸n global mediante npm**  
No utilizaremos esta opci贸n, ya que, pensando en una soluci贸n escalable y mantenible, preferimos una alternativa m谩s robusta.
   
### 2. **Instalaci贸n mediante Docker**  
Esta es la opci贸n que elegiremos por sus m煤ltiples ventajas:

  - Proporciona un entorno limpio para la instalaci贸n.
  - Facilita la configuraci贸n de la base de datos preferida.
  - Evita problemas de compatibilidad entre diferentes sistemas operativos, ya que Docker ofrece un entorno consistente.
  - Simplifica la migraci贸n a nuevos servidores o entornos.

Para instalar **n8n** con Docker, primero creamos un volumen para almacenar los datos de manera persistente:

```bash
docker volume create n8n_data
```

Luego ejecutamos el siguiente comando para iniciar el contenedor:

```bash
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Este comando:

- Crea un volumen llamado `n8n_data` para almacenar los datos localmente y asegurarse de que se conserven entre reinicios del contenedor.
- Descarga la imagen oficial de **n8n**.
- Inicia el contenedor y expone el servicio en el puerto **5678**.

Una vez en funcionamiento, se puede acceder a **n8n** en:

```
http://localhost:5678
```


### 3. **Instalaci贸n Self-hosted AI starter kit** 

#### 驴Qu茅 es el Self-hosted AI Starter Kit?

El **Self-hosted AI Starter Kit** es una soluci贸n de c贸digo abierto (proporcionada por n8n) dise帽ada para facilitar la implementaci贸n de infraestructuras de inteligencia artificial de manera local, sin depender de servicios en la nube.  
Proporciona un entorno preconfigurado que integra m煤ltiples componentes clave, como:

- Bases de datos (PostgreSQL, Redis, etc.)
- Almacenamiento vectorial
- Servidores de modelos de lenguaje (LLMs)
- Interfaces web de administraci贸n

Todo el sistema se despliega mediante contenedores **Docker**, lo que garantiza portabilidad, consistencia y facilidad de mantenimiento.  
El kit est谩 pensado para ser modular y escalable, adapt谩ndose tanto a proyectos personales como a entornos productivos de mayor escala.

se eligi贸 utilizar el **Self-hosted AI Starter Kit** debido a varias razones fundamentales:

- **Control total** sobre los datos y la infraestructura.
- **Evitar limitaciones** de plataformas en la nube, como restricciones de tokens, memoria o tiempo de ejecuci贸n.
- **Mayor privacidad** y **seguridad** de la informaci贸n procesada.
- **Facilidad de integraci贸n** con otras herramientas y sistemas propios.
- **Escalabilidad**, permitiendo crecer en recursos y capacidades a medida que el proyecto lo requiera.

Adem谩s, el enfoque basado en Docker permite que toda la infraestructura pueda ser levantada, replicada o migrada f谩cilmente entre distintos entornos.

#### Instalaci贸n del Self-hosted AI Starter Kit

El proceso de instalaci贸n del kit depende del hardware disponible, particularmente de si se cuenta o no con soporte de **GPU NVIDIA**.  
En este caso espec铆fico, se opt贸 por la opci贸n que permite **aprovechar la aceleraci贸n de GPU** mediante NVIDIA, para mejorar el rendimiento en la ejecuci贸n de modelos de IA.

Los pasos generales de instalaci贸n fueron los siguientes:

1. Clonaci贸n del repositorio oficial del proyecto:
   ```bash
    git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
    cd self-hosted-ai-starter-kit
   ```

2. Ejecutar n8n usando docker compose:
   
   Para usuarios con GPU NVIDIA:
   ```bash
    git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
    cd self-hosted-ai-starter-kit
    docker compose --profile gpu-nvidia up
   ```

Una vez en funcionamiento, se puede acceder a **n8n** en:

```
http://localhost:5678
```

## Conclusi贸n

n8n es una herramienta poderosa y vers谩til que facilita la integraci贸n de servicios y la creaci贸n de automatismos sin requerir gran experiencia en programaci贸n. En este proyecto, permite centralizar todas las tareas repetitivas relacionadas con el an谩lisis, resumen e indexaci贸n de papers cient铆ficos, funcionando como columna vertebral de la arquitectura de RAG implementada.


## Referencia
Si est谩s m谩s interesado conocer m谩s sobre n8n.

- [P谩gina principal](https://n8n.io/)
- [Documentaci贸n](https://docs.n8n.io/)
- [N8N GITHUB](https://github.com/n8n-io)
- [self-hosted-ai-starter-kit](https://github.com/n8n-io/self-hosted-ai-starter-kit)
