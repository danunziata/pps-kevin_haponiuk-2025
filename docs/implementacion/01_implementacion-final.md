## Requisitos Previos

Actualizaci√≥n del Sistema
```sh
sudo apt update
sudo apt upgrade
```

Instalaci√≥n de Python
```sh
sudo apt install python python3-pip python3-venv
```

Instalaci√≥n de Docker
```sh
sudo apt install docker.io
sudo systemctl enable docker
sudo systemctl start docker
docker --version
```

Instalaci√≥n de Docker-Compose
```sh
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose --version
```

## Puesta en Marcha

### Clonaci√≥n del Repositorio
```sh
git clone git@github.com:danunziata/pps-kevin_haponiuk-2025.git
cd pps-kevin_haponiuk-2025/src/self-hosted-ai-starter-kit
```

### Ejecuci√≥n con Docker Compose
El proyecto soporta dos perfiles de ejecuci√≥n seg√∫n el hardware disponible:

| Perfil | Comando | 
|--------|---------|
| **CPU** | `docker compose --profile cpu up` |
| **GPU NVIDIA (recomendado)** | `docker compose --profile gpu-nvidia up` | 

### Descarga de Modelos en Ollama
```sh
# Acceder al contenedor de Ollama
docker exec -it ollama bash

# Descargar modelos necesarios
ollama run llama3.1:8b
ollama run gemma3:1b
ollama run qwen3:8b
ollama pull nomic-embed-text
```

**Nota**: Al finalizar cada ejecuci√≥n de modelo, salir con `/bye`.

## Configuraci√≥n de Servicios

### N8N
1. Acceder a [http://localhost:5678](http://localhost:5678)
2. Configurar credenciales locales:
      - Email: prueba@gmail.com
      - First Name: Prueba
      - Last Name: Prueba
      - Password: Prueba123
3. Verificar que aparezca el workflow "Agent-AI-PPS_Kevin-Haponiuk"... Si no aparece, importar desde: `pps-kevin_haponiuk-2025/src/self-hosted-ai-starter-kit/n8n/backup/workflows/Agent-AI-PPS_Kevin-Haponiuk.json`

### Credenciales de Google
Configurar las credenciales de Google siguiendo la [gu√≠a de instalaci√≥n](../../pruebas/01_install-n8n/#credenciales-de-google).

### Verificaci√≥n de GROBID
1. **Prueba desde navegador**: [http://localhost:8070/api/isalive](http://localhost:8070/api/isalive) debe retornar `true`
2. **Prueba desde N8N**: Ejecutar el bloque "TEST GROBID" para verificar la conectividad

## Procesamiento de Datos

### Carga de Informaci√≥n
1. Configurar la carpeta de PDFs en el bloque "Search all Content"
2. Ejecutar el workflow "CARGA DE INFORMACI√ìN" en N8N
3. Verificar la carga en [http://localhost:6333/dashboard#/collections](http://localhost:6333/dashboard#/collections)

### Configuraci√≥n de PostgreSQL
Obtener la IP del servicio de postgres:
```sh
docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' self-hosted-ai-starter-kit-postgres-1
```

Configurar credenciales del nodo de Postgres en N8N:

   - Host: [IP obtenida]
   - Database: n8n
   - Username: root
   - Password: password

### PgAdmin (Opcional)
1. Acceder a [http://localhost:5050/](http://localhost:5050/)
2. Login: admin@admin.com / admin
3. Agregar nuevo servidor con la IP de postgres y mismos par√°metros utilizados en el punto anterior.

## Consulta al Agente

Existen dos formas de interactuar con el agente:

1. **Chat directo**: Usar el bloque "when chat message received" en N8N
2. **Webhook con OpenWebUI**: Configurar integraci√≥n externa

### Configuraci√≥n de OpenWebUI

Para poder hacer la consulta al agente mediante el bloque webhook, debemos configurar el servicio de OpenWebUI.

1. **Acceder a OpenWebUI**: Ir a `http://localhost:3000` y logearse con un mail y password.

2. **Crear nueva funci√≥n**: Ir abajo a la izquierda y entrar al **Admin Panel** ‚Üí **Functions** y crear una nueva funci√≥n.

3. **C√≥digo de la funci√≥n**: Copiar el siguiente c√≥digo en la funci√≥n:

    ```python
    # C√≥digo completo disponible en: src/self-hosted-ai-starter-kit/n8n-pipeline-function.py
    ```

4. **Configurar par√°metros**: Configure los siguientes par√°metros en la funci√≥n creada:

      - **Nombre**: "N8N Pipeline" 
      - **Descripci√≥n**: "Pipeline para interactuar con N8N"

5. **Acceder al bloque Webhook**: En N8N, localice y configure el bloque Webhook de la siguiente manera (copie el Test URL generado):

<p align="center">
  <img src="/images/config-n8n-openweb.png" width="80%">
</p>

En las configuraciones de la funci√≥n, utilice la URL copiada de N8N y realice el siguiente cambio:

   - Reemplace `localhost` por el nombre del contenedor de N8N (en este caso "n8n")
   - Mantenga el resto de configuraciones en valores por defecto

<p align="center">
  <img src="../images/function-2.png" width="60%">
</p>

**Activar el workflow**: Active el workflow en N8N para comenzar a recibir solicitudes:

<p align="center">
  <img src="/images/activate.png" width="50%">
</p>

**Configurar escucha**: Configure el workflow para escuchar y recibir respuestas externas:

<p align="center">
  <img src="../../images/execute.png" width="60%">
</p>

### Verificaci√≥n Final

Una vez completados todos los pasos anteriores, ya puede realizar consultas al agente directamente desde n8n o desde Open WebUI.

## üõë Detener la ejecuci√≥n

```bash
# Para perfil CPU
docker compose --profile cpu down

# Para perfil GPU NVIDIA
docker compose --profile gpu-nvidia down
```

## Puertos Utilizados

| Servicio | Puerto |
|----------|--------|
| N8N | 5678 |
| Ollama | 11434 |
| PgAdmin | 5050 |
| Qdrant | 6333 |
| Qdrant Search | 5000 |
| PostgreSQL | 5432 |
| OpenWebUI | 3000 |
| Grobid | 8070 |
| Cadvisor | 8081 |
| Prometheus | 9090 |
| Grafana | 3001 |

